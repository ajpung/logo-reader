{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "28c2e5e9-3080-405e-8b9c-83ad972190b4",
   "metadata": {},
   "source": [
    "## Check GPU presence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "fbcf1bda-cd2d-45cd-aa2c-97d82e5b81c7",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C:\\Users\\aaron\\AppData\\Local\\Programs\\Python\\Python311\\python.exe\n",
      "3.11.9 (tags/v3.11.9:de54cf5, Apr  2 2024, 10:12:12) [MSC v.1938 64 bit (AMD64)]\n",
      "PyTorch: 2.5.1+cu121\n",
      "Torchvision: 0.20.1+cu121\n",
      "CUDA available: True\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "print(sys.executable)\n",
    "print(sys.version)\n",
    "\n",
    "#import sys\n",
    "#!{sys.executable} -m pip uninstall torch torchvision torchaudio -y\n",
    "#!{sys.executable} -m pip install torch torchvision torchaudio --index-url https://download.pytorch.org/whl/cu121\n",
    "\n",
    "import torch\n",
    "import torchvision\n",
    "\n",
    "print(f\"PyTorch: {torch.__version__}\")\n",
    "print(f\"Torchvision: {torchvision.__version__}\")\n",
    "print(f\"CUDA available: {torch.cuda.is_available()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e728c549-c55b-47a4-8bca-f6a705c642ff",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "from torch.utils.data import Dataset\n",
    "\n",
    "# Custom Dataset class\n",
    "class ChipDataset(Dataset):\n",
    "    def __init__(self, image_paths, labels, transform=None):\n",
    "        self.image_paths = image_paths\n",
    "        self.labels = labels\n",
    "        self.transform = transform\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.image_paths)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        img_path = self.image_paths[idx]\n",
    "        image = Image.open(img_path).convert('RGB')\n",
    "        \n",
    "        if self.transform:\n",
    "            image = self.transform(image)\n",
    "        \n",
    "        label = torch.tensor(self.labels[idx], dtype=torch.long)  # Add dtype=torch.long\n",
    "        return image, label"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c5ae40e-63bf-4fd1-8eeb-e88e9d728a44",
   "metadata": {},
   "source": [
    "## Collect / analyze image database\n",
    "\n",
    "Collect all images in the database, count the number of samples in each brand, and present in a plot. For this model, each model must have a minimum of 20 images to be used."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87ae2ccb-3188-42fd-ab4d-09055d046e09",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "!pip install --upgrade pip --quiet\n",
    "\n",
    "# Section 1: Data Augmentation & Dataset Setup\n",
    "import os\n",
    "from PIL import Image\n",
    "import pandas as pd\n",
    "from collections import Counter\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# Define your data directory\n",
    "DATA_DIR = './components/'\n",
    "\n",
    "# Scan the directory and build the dataset directly from files\n",
    "brand_counts = Counter()\n",
    "all_files = []\n",
    "\n",
    "for filename in os.listdir(DATA_DIR):\n",
    "    if filename.endswith('.png'):\n",
    "        brand = filename.split('_')[0]\n",
    "        brand_counts[brand] += 1\n",
    "        all_files.append(filename)\n",
    "\n",
    "# Create dataframe from actual files\n",
    "df = pd.DataFrame([\n",
    "    {'Brand': brand, 'Moniker': brand, 'Count': count}\n",
    "    for brand, count in brand_counts.items()\n",
    "]).sort_values('Count', ascending=False)\n",
    "\n",
    "print(f\"Found {len(all_files)} total images across {len(df)} brands\")\n",
    "\n",
    "# Create visualization\n",
    "plt.figure(figsize=(24, 5))\n",
    "sns.set_style(\"whitegrid\")\n",
    "\n",
    "# Create bar plot\n",
    "ax = sns.barplot(data=df, x='Brand', y='Count', hue='Brand', palette='viridis', legend=False)\n",
    "\n",
    "# Customize the plot\n",
    "plt.xticks(rotation=90, ha='right')\n",
    "plt.xlabel('Brand/Manufacturer', fontsize=12, fontweight='bold')\n",
    "plt.ylabel('Number of Images', fontsize=12, fontweight='bold')\n",
    "plt.title('Actual Image Count per IC Manufacturer (from ./components/)', fontsize=14, fontweight='bold', pad=20)\n",
    "\n",
    "# Add value labels on top of bars\n",
    "for i, v in enumerate(df['Count']):\n",
    "    ax.text(i, v + 0.5, str(v), ha='center', va='bottom', fontsize=8)\n",
    "\n",
    "# Add threshold line\n",
    "plt.axhline(y=20, color='red', linestyle='--', linewidth=2, alpha=0.7, label='Threshold (‚â•20 for training)')\n",
    "plt.legend()\n",
    "\n",
    "\n",
    "# Filter to brands with >= 20 images\n",
    "min_df = df[df['Count'] >= 20].copy()\n",
    "\n",
    "# Get list of valid brands (these will be your classes)\n",
    "valid_brands = min_df['Moniker'].tolist()\n",
    "brand_to_idx = {brand: idx for idx, brand in enumerate(sorted(valid_brands))}\n",
    "idx_to_brand = {idx: brand for brand, idx in brand_to_idx.items()}\n",
    "\n",
    "# Collect all valid images (only from brands with >= 20 images)\n",
    "image_paths = []\n",
    "labels = []\n",
    "\n",
    "for filename in all_files:\n",
    "    brand = filename.split('_')[0]\n",
    "    \n",
    "    if brand in brand_to_idx:\n",
    "        image_paths.append(os.path.join(DATA_DIR, filename))\n",
    "        labels.append(brand_to_idx[brand])\n",
    "\n",
    "print(f\"\\nTotal images for training: {len(image_paths)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d78b2e8b-f8ee-4bda-aa5c-99770d2d4ec1",
   "metadata": {},
   "source": [
    "## Reduce dataset to minimum viable brands\n",
    "\n",
    "To be used in the model, each brand must contain a minimum of 20 samples. Brands with less than 20 samples are discarded from the dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea0061a3-7f19-4516-ae72-e826142e6d87",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "# Section 3: Download/Build the Model\n",
    "import torch.nn as nn\n",
    "from torchvision import models\n",
    "\n",
    "# Check if GPU is available\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(f\"Using device: {device}\")\n",
    "if device.type == 'cuda':\n",
    "    print(f\"GPU: {torch.cuda.get_device_name(0)}\")\n",
    "    print(f\"Memory: {torch.cuda.get_device_properties(0).total_memory / 1024**3:.2f} GB\")\n",
    "\n",
    "# Load pretrained ResNet-18\n",
    "print(f\"\\n{'='*60}\")\n",
    "print(\"Loading ResNet-18 with ImageNet pretrained weights...\")\n",
    "\n",
    "model = models.resnet18(pretrained=True)\n",
    "\n",
    "# Freeze early layers (optional - keeps ImageNet features)\n",
    "for param in model.parameters():\n",
    "    param.requires_grad = False\n",
    "\n",
    "# Replace the final fully connected layer\n",
    "num_classes = len(brand_to_idx)\n",
    "model.fc = nn.Linear(model.fc.in_features, num_classes)\n",
    "\n",
    "# Move model to GPU/CPU\n",
    "model = model.to(device)\n",
    "\n",
    "print(f\"Model architecture modified:\")\n",
    "print(f\"  Original output: 1000 classes (ImageNet)\")\n",
    "print(f\"  New output: {num_classes} classes (IC brands)\")\n",
    "print(f\"  Frozen layers: Early conv layers (transfer learning)\")\n",
    "print(f\"  Trainable layers: Final FC layer\")\n",
    "\n",
    "# Count parameters\n",
    "total_params = sum(p.numel() for p in model.parameters())\n",
    "trainable_params = sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
    "\n",
    "print(f\"\\nModel parameters:\")\n",
    "print(f\"  Total parameters: {total_params:,}\")\n",
    "print(f\"  Trainable parameters: {trainable_params:,}\")\n",
    "print(f\"  Frozen parameters: {total_params - trainable_params:,}\")\n",
    "\n",
    "# Define loss function and optimizer\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(model.fc.parameters(), lr=0.001)\n",
    "\n",
    "# Learning rate scheduler\n",
    "scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(\n",
    "    optimizer, \n",
    "    mode='min',\n",
    "    factor=0.5,\n",
    "    patience=3,\n",
    "    verbose=True\n",
    ")\n",
    "\n",
    "print(f\"\\nTraining configuration:\")\n",
    "print(f\"  Loss function: CrossEntropyLoss\")\n",
    "print(f\"  Optimizer: Adam (lr=0.001)\")\n",
    "print(f\"  Scheduler: ReduceLROnPlateau (factor=0.5, patience=3)\")\n",
    "print(f\"\\nModel ready for training!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb1da73b-7253-4161-a967-775127fc061b",
   "metadata": {},
   "source": [
    "## Split dataset into train / test / validation (80 / (80/20))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2e5179a-58c9-4cce-9aee-cc786312d1aa",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "# Section 2: Train/Test/Validation Split\n",
    "from sklearn.model_selection import train_test_split\n",
    "import numpy as np\n",
    "from torchvision import transforms\n",
    "\n",
    "# Convert to numpy arrays for easier manipulation\n",
    "image_paths = np.array(image_paths)\n",
    "labels = np.array(labels)\n",
    "\n",
    "print(f\"Total dataset: {len(image_paths)} images\")\n",
    "print(f\"Number of classes: {len(brand_to_idx)}\")\n",
    "\n",
    "# First split: 80% train+val, 20% test\n",
    "# Stratify to ensure each brand is represented proportionally in each split\n",
    "train_val_paths, test_paths, train_val_labels, test_labels = train_test_split(\n",
    "    image_paths, \n",
    "    labels, \n",
    "    test_size=0.2,  # 20% for test\n",
    "    stratify=labels,  # Maintain class distribution\n",
    "    random_state=42\n",
    ")\n",
    "\n",
    "# Second split: Split train+val into 80% train, 20% val\n",
    "# From the remaining 80%, take 20% for validation (which is 16% of total)\n",
    "train_paths, val_paths, train_labels, val_labels = train_test_split(\n",
    "    train_val_paths,\n",
    "    train_val_labels,\n",
    "    test_size=0.2,  # 20% of train_val = 16% of total\n",
    "    stratify=train_val_labels,\n",
    "    random_state=42\n",
    ")\n",
    "\n",
    "# Final split: ~64% train, ~16% val, ~20% test\n",
    "print(f\"\\n{'='*60}\")\n",
    "print(f\"Split Summary:\")\n",
    "print(f\"  Training:   {len(train_paths)} images ({len(train_paths)/len(image_paths)*100:.1f}%)\")\n",
    "print(f\"  Validation: {len(val_paths)} images ({len(val_paths)/len(image_paths)*100:.1f}%)\")\n",
    "print(f\"  Test:       {len(test_paths)} images ({len(test_paths)/len(image_paths)*100:.1f}%)\")\n",
    "\n",
    "# Verify stratification - check distribution across splits\n",
    "print(f\"\\n{'='*60}\")\n",
    "print(f\"Verifying stratification (samples per brand):\")\n",
    "print(f\"{'Brand':<15} {'Train':<8} {'Val':<8} {'Test':<8} {'Total':<8}\")\n",
    "print(f\"{'-'*60}\")\n",
    "\n",
    "for brand in sorted(valid_brands):\n",
    "    brand_idx = brand_to_idx[brand]\n",
    "    train_count = np.sum(train_labels == brand_idx)\n",
    "    val_count = np.sum(val_labels == brand_idx)\n",
    "    test_count = np.sum(test_labels == brand_idx)\n",
    "    total = train_count + val_count + test_count\n",
    "    print(f\"{brand:<15} {train_count:<8} {val_count:<8} {test_count:<8} {total:<8}\")\n",
    "\n",
    "# Training augmentations\n",
    "train_transforms = transforms.Compose([\n",
    "    transforms.Resize((224, 224)),\n",
    "    transforms.RandomHorizontalFlip(p=0.5),\n",
    "    transforms.RandomRotation(degrees=15),\n",
    "    transforms.ColorJitter(brightness=0.3, contrast=0.3, saturation=0.3, hue=0.1),\n",
    "    transforms.RandomAffine(degrees=0, translate=(0.1, 0.1), scale=(0.9, 1.1)),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
    "])\n",
    "\n",
    "# Validation/Test augmentations\n",
    "val_test_transforms = transforms.Compose([\n",
    "    transforms.Resize((224, 224)),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
    "])\n",
    "\n",
    "# Create datasets with appropriate transforms\n",
    "train_dataset = ChipDataset(train_paths, train_labels, transform=train_transforms)\n",
    "val_dataset = ChipDataset(val_paths, val_labels, transform=val_test_transforms)\n",
    "test_dataset = ChipDataset(test_paths, test_labels, transform=val_test_transforms)\n",
    "\n",
    "print(f\"\\n{'='*60}\")\n",
    "print(f\"Datasets created:\")\n",
    "print(f\"  Training dataset:   {len(train_dataset)} samples (with augmentation)\")\n",
    "print(f\"  Validation dataset: {len(val_dataset)} samples (no augmentation)\")\n",
    "print(f\"  Test dataset:       {len(test_dataset)} samples (no augmentation)\")\n",
    "\n",
    "# Create data loaders\n",
    "BATCH_SIZE = 32\n",
    "\n",
    "train_loader = torch.utils.data.DataLoader(\n",
    "    train_dataset,\n",
    "    batch_size=BATCH_SIZE,\n",
    "    shuffle=True,\n",
    "    num_workers=0,  # Changed from 4 to 0 (Windows fix)\n",
    "    pin_memory=True\n",
    ")\n",
    "\n",
    "val_loader = torch.utils.data.DataLoader(\n",
    "    val_dataset,\n",
    "    batch_size=BATCH_SIZE,\n",
    "    shuffle=False,\n",
    "    num_workers=0,  # Changed from 4 to 0\n",
    "    pin_memory=True\n",
    ")\n",
    "\n",
    "test_loader = torch.utils.data.DataLoader(\n",
    "    test_dataset,\n",
    "    batch_size=BATCH_SIZE,\n",
    "    shuffle=False,\n",
    "    num_workers=0,  # Changed from 4 to 0\n",
    "    pin_memory=True\n",
    ")\n",
    "\n",
    "print(f\"\\nDataLoaders created:\")\n",
    "print(f\"  Batch size: {BATCH_SIZE}\")\n",
    "print(f\"  Training batches:   {len(train_loader)}\")\n",
    "print(f\"  Validation batches: {len(val_loader)}\")\n",
    "print(f\"  Test batches:       {len(test_loader)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7bf30329-72b5-446f-8f8a-ba2e85fdf242",
   "metadata": {},
   "source": [
    "## Implement different transfer learning models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db92f14c-eb92-4f3b-b2eb-6b574651b400",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Section: Multi-Model Comparison\n",
    "\n",
    "# Section: Multi-Model Comparison\n",
    "import torch.nn as nn\n",
    "from torchvision import models\n",
    "import pandas as pd\n",
    "import time\n",
    "from sklearn.metrics import f1_score  # ADD THIS LINE\n",
    "\n",
    "# Define models to test\n",
    "models_to_test = {\n",
    "    'ResNet-18': lambda: models.resnet18(pretrained=True),\n",
    "    'ResNet-34': lambda: models.resnet34(pretrained=True),\n",
    "    'ResNet-50': lambda: models.resnet50(pretrained=True),\n",
    "    'EfficientNet-B0': lambda: models.efficientnet_b0(pretrained=True),\n",
    "    'EfficientNet-B2': lambda: models.efficientnet_b2(pretrained=True),\n",
    "    'EfficientNet-B4': lambda: models.efficientnet_b4(pretrained=True),\n",
    "    'EfficientNet-B6': lambda: models.efficientnet_b6(pretrained=True),\n",
    "    'EfficientNet-B7': lambda: models.efficientnet_b7(pretrained=True),    \n",
    "    'MobileNet-V3': lambda: models.mobilenet_v3_large(pretrained=True),\n",
    "    'DenseNet-121': lambda: models.densenet121(pretrained=True),\n",
    "}\n",
    "\n",
    "results = []\n",
    "\n",
    "for model_name, model_fn in models_to_test.items():\n",
    "    print(f\"\\n{'='*60}\")\n",
    "    print(f\"Training {model_name}\")\n",
    "    print(f\"{'='*60}\\n\")\n",
    "    \n",
    "    # Load model\n",
    "    model = model_fn()\n",
    "    \n",
    "    # Modify final layer based on architecture\n",
    "    num_classes = len(brand_to_idx)\n",
    "    \n",
    "    if 'resnet' in model_name.lower():\n",
    "        # Freeze early layers\n",
    "        for name, param in model.named_parameters():\n",
    "            if 'layer1' in name or 'layer2' in name or 'conv1' in name or 'bn1' in name:\n",
    "                param.requires_grad = False\n",
    "        model.fc = nn.Linear(model.fc.in_features, num_classes)\n",
    "        \n",
    "    elif 'efficientnet' in model_name.lower():\n",
    "        # Freeze early layers\n",
    "        for i, child in enumerate(model.features.children()):\n",
    "            if i < 5:  # Freeze first 5 blocks\n",
    "                for param in child.parameters():\n",
    "                    param.requires_grad = False\n",
    "        model.classifier[1] = nn.Linear(model.classifier[1].in_features, num_classes)\n",
    "        \n",
    "    elif 'mobilenet' in model_name.lower():\n",
    "        # Freeze early layers\n",
    "        for i, child in enumerate(model.features.children()):\n",
    "            if i < 10:  # Freeze first 10 blocks\n",
    "                for param in child.parameters():\n",
    "                    param.requires_grad = False\n",
    "        model.classifier[3] = nn.Linear(model.classifier[3].in_features, num_classes)\n",
    "        \n",
    "    elif 'densenet' in model_name.lower():\n",
    "        # Freeze early layers\n",
    "        for name, param in model.named_parameters():\n",
    "            if 'denseblock1' in name or 'denseblock2' in name:\n",
    "                param.requires_grad = False\n",
    "        model.classifier = nn.Linear(model.classifier.in_features, num_classes)\n",
    "    \n",
    "    model = model.to(device)\n",
    "    \n",
    "    # Training setup\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    optimizer = torch.optim.Adam(\n",
    "        filter(lambda p: p.requires_grad, model.parameters()),\n",
    "        lr=0.0001\n",
    "    )\n",
    "    scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(\n",
    "        optimizer, mode='min', factor=0.5, patience=5, verbose=False\n",
    "    )\n",
    "    \n",
    "    # Train for fewer epochs (for comparison)\n",
    "    NUM_EPOCHS = 30\n",
    "    best_val_acc = 0.0\n",
    "    \n",
    "    train_start = time.time()\n",
    "    \n",
    "    for epoch in range(NUM_EPOCHS):\n",
    "        # Training\n",
    "        model.train()\n",
    "        train_loss = 0.0\n",
    "        train_correct = 0\n",
    "        train_total = 0\n",
    "        \n",
    "        for images, labels_batch in train_loader:\n",
    "            images = images.to(device)\n",
    "            labels_batch = labels_batch.to(device)\n",
    "            \n",
    "            optimizer.zero_grad()\n",
    "            outputs = model(images)\n",
    "            loss = criterion(outputs, labels_batch)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            \n",
    "            train_loss += loss.item()\n",
    "            _, predicted = torch.max(outputs.data, 1)\n",
    "            train_total += labels_batch.size(0)\n",
    "            train_correct += (predicted == labels_batch).sum().item()\n",
    "        \n",
    "        train_acc = 100 * train_correct / train_total\n",
    "        \n",
    "        # Validation\n",
    "        model.eval()\n",
    "        val_loss = 0.0\n",
    "        val_correct = 0\n",
    "        val_total = 0\n",
    "        \n",
    "        with torch.no_grad():\n",
    "            for images, labels_batch in val_loader:\n",
    "                images = images.to(device)\n",
    "                labels_batch = labels_batch.to(device)\n",
    "                \n",
    "                outputs = model(images)\n",
    "                loss = criterion(outputs, labels_batch)\n",
    "                \n",
    "                val_loss += loss.item()\n",
    "                _, predicted = torch.max(outputs.data, 1)\n",
    "                val_total += labels_batch.size(0)\n",
    "                val_correct += (predicted == labels_batch).sum().item()\n",
    "        \n",
    "        val_acc = 100 * val_correct / val_total\n",
    "        scheduler.step(val_loss / len(val_loader))\n",
    "        \n",
    "        if val_acc > best_val_acc:\n",
    "            best_val_acc = val_acc\n",
    "        \n",
    "        # Print progress every 5 epochs\n",
    "        if (epoch + 1) % 5 == 0:\n",
    "            print(f\"Epoch {epoch+1}/{NUM_EPOCHS}: Train Acc={train_acc:.2f}%, Val Acc={val_acc:.2f}%\")\n",
    "    \n",
    "    train_time = time.time() - train_start\n",
    "    \n",
    "    # Test evaluation\n",
    "    model.eval()\n",
    "    test_correct = 0\n",
    "    test_total = 0\n",
    "    all_preds = []\n",
    "    all_labels = []\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for images, labels_batch in test_loader:\n",
    "            images = images.to(device)\n",
    "            labels_batch = labels_batch.to(device)\n",
    "            \n",
    "            outputs = model(images)\n",
    "            _, predicted = torch.max(outputs.data, 1)\n",
    "            test_total += labels_batch.size(0)\n",
    "            test_correct += (predicted == labels_batch).sum().item()\n",
    "            \n",
    "            all_preds.extend(predicted.cpu().numpy())\n",
    "            all_labels.extend(labels_batch.cpu().numpy())\n",
    "    \n",
    "    test_acc = 100 * test_correct / test_total\n",
    "    test_f1 = f1_score(all_labels, all_preds, average='weighted')\n",
    "    \n",
    "    # Count parameters\n",
    "    total_params = sum(p.numel() for p in model.parameters())\n",
    "    trainable_params = sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
    "    \n",
    "    results.append({\n",
    "        'Model': model_name,\n",
    "        'Test Accuracy': f'{test_acc:.2f}%',\n",
    "        'Test F1': f'{test_f1:.4f}',\n",
    "        'Best Val Acc': f'{best_val_acc:.2f}%',\n",
    "        'Total Params': f'{total_params/1e6:.2f}M',\n",
    "        'Trainable Params': f'{trainable_params/1e6:.2f}M',\n",
    "        'Training Time': f'{train_time:.1f}s'\n",
    "    })\n",
    "    \n",
    "    print(f\"\\n{model_name} Results:\")\n",
    "    print(f\"  Test Accuracy: {test_acc:.2f}%\")\n",
    "    print(f\"  Test F1: {test_f1:.4f}\")\n",
    "    print(f\"  Training Time: {train_time:.1f}s\\n\")\n",
    "\n",
    "# Display results table\n",
    "print(f\"\\n{'='*80}\")\n",
    "print(\"MODEL COMPARISON SUMMARY\")\n",
    "print(f\"{'='*80}\\n\")\n",
    "\n",
    "df_results = pd.DataFrame(results)\n",
    "print(df_results.to_string(index=False))\n",
    "\n",
    "# Find best model\n",
    "best_idx = df_results['Test F1'].str.replace('%', '').astype(float).idxmax()\n",
    "print(f\"\\nüèÜ Best Model: {df_results.loc[best_idx, 'Model']} \"\n",
    "      f\"(Test Acc: {df_results.loc[best_idx, 'Test Accuracy']}, \"\n",
    "      f\"F1: {df_results.loc[best_idx, 'Test F1']})\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ef9a161-5697-4597-8cfe-7e0890cf7f6c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
